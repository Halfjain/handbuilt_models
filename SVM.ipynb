{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from libsvm.svmutil import svm_read_problem\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "\n",
    "def cost_gradient(W, X_batch, Y_batch):\n",
    "    if type(Y_batch) == np.float64:\n",
    "        Y_batch = np.array([Y_batch])\n",
    "        X_batch = np.array([X_batch])\n",
    "\n",
    "    distance = 1 - (Y_batch * np.dot(X_batch, W))\n",
    "    dw = np.zeros(len(W))\n",
    "\n",
    "    for ind, d in enumerate(distance):\n",
    "        if max(0, d) == 0:\n",
    "            di = W\n",
    "        else:\n",
    "            di = W - (regularization_strength * Y_batch[ind] * X_batch[ind])\n",
    "        dw += di\n",
    "\n",
    "    dw = dw/len(Y_batch)\n",
    "    return dw\n",
    "\n",
    "\n",
    "\n",
    "def compute_cost(W, X, Y):\n",
    "    N = X.shape[0]\n",
    "    distances = 1 - Y * (np.dot(X, W))\n",
    "    distances[distances < 0] = 0\n",
    "    hinge_loss = regularization_strength * (np.sum(distances) / N)\n",
    "\n",
    "    cost = 1 / 2 * np.dot(W, W) + hinge_loss\n",
    "    return cost\n",
    "\n",
    "\n",
    "\n",
    "def sgd(features, outputs):\n",
    "    max_iters = 1000\n",
    "    weights = np.zeros(features.shape[1])\n",
    "    nth = 0\n",
    "    prev_cost = float(\"inf\")\n",
    "    cost_threshold = 0.001\n",
    "    for iter in range(1, max_iters):\n",
    "        X, Y = shuffle(features, outputs)\n",
    "        for ind, x in enumerate(X):\n",
    "            ascent = cost_gradient(weights, x, Y[ind])\n",
    "            weights = weights - (learning_rate * ascent)\n",
    "\n",
    "        if iter == 2 ** nth or iter == max_iters - 1:\n",
    "            cost = compute_cost(weights, features, outputs)\n",
    "            #print(\"iter {} Cost = {}\".format(iter, cost))\n",
    "            if abs(prev_cost - cost) < cost_threshold * prev_cost:\n",
    "                return weights\n",
    "            prev_cost = cost\n",
    "            nth += 1\n",
    "\n",
    "    return weights\n",
    "\n",
    "\n",
    "regularization_strength = 10\n",
    "learning_rate = 0.00001\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=======mnist.scale.bz2=======\n",
      "18000 test case predicted.\n",
      "11569 are correct.\n",
      "Accuracy = 64.3%\n"
     ]
    }
   ],
   "source": [
    "print('\\n=======mnist.scale.bz2=======')\n",
    "\n",
    "y_raw, x_raw = svm_read_problem('mnist.scale')\n",
    "\n",
    "y = np.array(y_raw)\n",
    "x = np.zeros((len(y_raw), 780))\n",
    "for i in range(len(y_raw)):\n",
    "    line = x_raw[i]\n",
    "    for k, v in line.items():\n",
    "        x[i][k - 1] = v\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.3)\n",
    "\n",
    "y_train1 = np.copy(y_train)\n",
    "y_train1[y_train1!=1] = -1\n",
    "y_train1[y_train1!=-1] = 1\n",
    "\n",
    "y_train2 = np.copy(y_train)\n",
    "y_train2[y_train2!=2] = -1\n",
    "y_train2[y_train2!=-1] = 1\n",
    "\n",
    "y_train3 = np.copy(y_train)\n",
    "y_train3[y_train3!=3] = -1\n",
    "y_train3[y_train3!=-1] = 1\n",
    "\n",
    "W1 = sgd(x_train, y_train1)\n",
    "W2 = sgd(x_train, y_train2)\n",
    "W3 = sgd(x_train, y_train3)\n",
    "\n",
    "\n",
    "predicted = np.zeros(len(y_test))\n",
    "for i in range(len(y_test)):\n",
    "    pred = np.zeros(3)\n",
    "\n",
    "    pred[0] = np.dot(x_test[i], W1)\n",
    "    pred[1] = np.dot(x_test[i], W2)\n",
    "    pred[2] = np.dot(x_test[i], W3)\n",
    "    predicted[i] = np.argmax(pred) + 1\n",
    "\n",
    "print(len(predicted), ' test case predicted.', sep='')\n",
    "correct_num = np.sum(predicted == y_test)\n",
    "print(correct_num, ' are correct.', sep='')\n",
    "print('Accuracy = ', np.round(correct_num * 100 / len(predicted)), '%', sep='')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "correct = (predicted == y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[   0, 2457, 5675, 4546],\n",
       "       [   0, 2007, 1637, 1678],\n",
       "       [   0,    0,    0,    0],\n",
       "       [   0,    0,    0,    0]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(correct, predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
